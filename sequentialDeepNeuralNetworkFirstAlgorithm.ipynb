{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFPnhoZow33B",
        "outputId": "952a6b41-ffa7-40e4-cb87-4cceac0b4b21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10] - Sequential Loss: 70.9535\n",
            "Epoch [2/10] - Sequential Loss: 68.3578\n",
            "Epoch [3/10] - Sequential Loss: 67.8143\n",
            "Epoch [4/10] - Sequential Loss: 67.4693\n",
            "Epoch [5/10] - Sequential Loss: 67.1701\n",
            "Epoch [6/10] - Sequential Loss: 66.8987\n",
            "Epoch [7/10] - Sequential Loss: 66.7001\n",
            "Epoch [8/10] - Sequential Loss: 66.6154\n",
            "Epoch [9/10] - Sequential Loss: 66.3425\n",
            "Epoch [10/10] - Sequential Loss: 66.1101\n",
            "üê¢ Sequential Execution Time: 417.56 seconds\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import time\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# üöÄ Start Timer for Sequential Execution\n",
        "start_time = time.time()\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/HighPerformanceMachineLearning/CrimeDatafrom2020toPresent.csv')\n",
        "\n",
        "# Convert DATE OCC to datetime format\n",
        "df['DATE OCC'] = pd.to_datetime(df['DATE OCC'], errors='coerce')\n",
        "\n",
        "# Extract time features\n",
        "df['Year_OCC'] = df['DATE OCC'].dt.year\n",
        "df['Month_OCC'] = df['DATE OCC'].dt.month\n",
        "df['Day_OCC'] = df['DATE OCC'].dt.day\n",
        "df['Hour_OCC'] = df['TIME OCC'] // 100  # Convert HHMM to hours\n",
        "\n",
        "# Count crimes per location\n",
        "crime_counts = df.groupby(['LAT', 'LON']).size()\n",
        "\n",
        "# Assign Crime Risk Scores (1-10) and scale to 1-5\n",
        "df['Crime_Risk'] = df.set_index(['LAT', 'LON']).index.map(lambda x: crime_counts.get(x, 0))\n",
        "df['Crime_Risk'] = np.ceil(10 * (df['Crime_Risk'] / df['Crime_Risk'].max())).astype(int)\n",
        "df['Crime_Risk'] = df['Crime_Risk'].clip(1, 10)\n",
        "df['Crime_Risk'] = np.ceil(df['Crime_Risk'] / 2).astype(int)\n",
        "\n",
        "# Normalize `Crime_Risk` to 0-1\n",
        "df['Crime_Risk'] = (df['Crime_Risk'] - 1) / 4\n",
        "\n",
        "# Normalize features\n",
        "features = ['Year_OCC', 'Month_OCC', 'Day_OCC', 'Hour_OCC', 'LAT', 'LON']\n",
        "scaler = StandardScaler()\n",
        "df[features] = scaler.fit_transform(df[features])\n",
        "\n",
        "# Train-Test Split\n",
        "train_df, _ = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define Dataset\n",
        "class CrimeDatasetRegression(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.x = torch.tensor(data[features].values, dtype=torch.float32)\n",
        "        self.y = torch.tensor(data['Crime_Risk'].values, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx], self.y[idx]\n",
        "\n",
        "# Create DataLoader (Single-Threaded, No Parallelism)\n",
        "train_dataset = CrimeDatasetRegression(train_df)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0, pin_memory=False)\n",
        "\n",
        "# Define Regression Model\n",
        "class CrimeRiskRegression(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super(CrimeRiskRegression, self).__init__()\n",
        "        self.layer1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.layer2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.output_layer = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.output_layer(x)\n",
        "        return torch.sigmoid(x)\n",
        "\n",
        "# üöÄ Model Initialization (CPU Only)\n",
        "device = torch.device(\"cpu\")\n",
        "model = CrimeRiskRegression(input_dim=6, hidden_dim=128).to(device)\n",
        "\n",
        "# Loss Function & Optimizer\n",
        "criterion = nn.HuberLoss(delta=1.0)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.002)\n",
        "\n",
        "# Training Loop (Sequential Execution)\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for x_batch, y_batch in train_loader:\n",
        "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(x_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}] - Sequential Loss: {total_loss:.4f}')\n",
        "\n",
        "# üöÄ End Timer\n",
        "sequential_time = time.time() - start_time\n",
        "print(f\"üê¢ Sequential Execution Time: {sequential_time:.2f} seconds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert predictions from 0-1 scale back to 1-5\n",
        "def convert_predictions(preds):\n",
        "    return (preds * 4) + 1  # Scale back to 1-5\n",
        "\n",
        "# üöÄ Convert Predictions Back to 1-5 Scale (Sequential Execution)\n",
        "model.eval()  # Set model to evaluation mode\n",
        "sample_input = torch.tensor([[0.2, -1.1, 0.5, 0.8, 1.3, -0.5]], dtype=torch.float32).to(device)\n",
        "output = model(sample_input)\n",
        "converted_output = convert_predictions(output)\n",
        "\n",
        "print(f\"üê¢ Raw Model Output (Sequential): {output.item():.4f}\")\n",
        "print(f\"üê¢ Converted Prediction (Sequential, 1-5 Scale): {converted_output.item():.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCFTUaTi6M22",
        "outputId": "31887084-7795-4cd1-872d-8f30262a18a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üê¢ Raw Model Output (Sequential): 0.5066\n",
            "üê¢ Converted Prediction (Sequential, 1-5 Scale): 3.03\n"
          ]
        }
      ]
    }
  ]
}