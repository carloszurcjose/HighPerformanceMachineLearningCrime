{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qz0gzqK6wVM0",
        "outputId": "9fe3a39d-2625-4d1c-e82a-a21661afb01d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10] - Parallel Loss: 37.0157\n",
            "Epoch [2/10] - Parallel Loss: 36.8928\n",
            "Epoch [3/10] - Parallel Loss: 36.8934\n",
            "Epoch [4/10] - Parallel Loss: 36.8898\n",
            "Epoch [5/10] - Parallel Loss: 36.8892\n",
            "Epoch [6/10] - Parallel Loss: 36.8946\n",
            "Epoch [7/10] - Parallel Loss: 36.8898\n",
            "Epoch [8/10] - Parallel Loss: 36.8892\n",
            "Epoch [9/10] - Parallel Loss: 36.8988\n",
            "Epoch [10/10] - Parallel Loss: 36.9012\n",
            "ðŸ”¥ Optimized Parallel Execution Time: 248.94 seconds\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import time\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import multiprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ðŸš€ Start Timer for Parallel Execution\n",
        "start_time = time.time()\n",
        "\n",
        "# ðŸš€ Enable GPU & Optimizations\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.backends.cudnn.benchmark = True  # Optimize cuDNN operations\n",
        "torch.backends.cudnn.enabled = True    # Enable cuDNN acceleration\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/HighPerformanceMachineLearning/CrimeDatafrom2020toPresent.csv')\n",
        "\n",
        "# Convert DATE OCC to datetime format\n",
        "df['DATE OCC'] = pd.to_datetime(df['DATE OCC'], errors='coerce')\n",
        "\n",
        "# Extract time features\n",
        "df['Year_OCC'] = df['DATE OCC'].dt.year\n",
        "df['Month_OCC'] = df['DATE OCC'].dt.month\n",
        "df['Day_OCC'] = df['DATE OCC'].dt.day\n",
        "df['Hour_OCC'] = df['TIME OCC'] // 100  # Convert HHMM to hours\n",
        "\n",
        "# Count crimes per location\n",
        "crime_counts = df.groupby(['LAT', 'LON']).size()\n",
        "\n",
        "# Assign Crime Risk Scores (1-10) and scale to 1-5\n",
        "df['Crime_Risk'] = df.set_index(['LAT', 'LON']).index.map(lambda x: crime_counts.get(x, 0))\n",
        "df['Crime_Risk'] = np.ceil(10 * (df['Crime_Risk'] / df['Crime_Risk'].max())).astype(int)\n",
        "df['Crime_Risk'] = df['Crime_Risk'].clip(1, 10)\n",
        "df['Crime_Risk'] = np.ceil(df['Crime_Risk'] / 2).astype(int)\n",
        "\n",
        "# Normalize `Crime_Risk` to 0-1\n",
        "df['Crime_Risk'] = (df['Crime_Risk'] - 1) / 4\n",
        "\n",
        "# Normalize features\n",
        "features = ['Year_OCC', 'Month_OCC', 'Day_OCC', 'Hour_OCC', 'LAT', 'LON']\n",
        "scaler = StandardScaler()\n",
        "df[features] = scaler.fit_transform(df[features])\n",
        "\n",
        "# Train-Test Split\n",
        "train_df, _ = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define Dataset\n",
        "class CrimeDatasetRegression(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.x = torch.tensor(data[features].values, dtype=torch.float32)\n",
        "        self.y = torch.tensor(data['Crime_Risk'].values, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx], self.y[idx]\n",
        "\n",
        "# ðŸš€ Auto-adjust DataLoader workers\n",
        "num_workers = min(4, multiprocessing.cpu_count())  # Set to 4 or half of CPU cores\n",
        "train_dataset = CrimeDatasetRegression(train_df)\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "# Define Regression Model\n",
        "class CrimeRiskRegression(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super(CrimeRiskRegression, self).__init__()\n",
        "        self.layer1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.layer2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.output_layer = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.output_layer(x)\n",
        "        return torch.sigmoid(x)\n",
        "\n",
        "# ðŸš€ Model Initialization (GPU + Multi-GPU Support)\n",
        "model = CrimeRiskRegression(input_dim=6, hidden_dim=512).to(device)  # Increased hidden_dim for better GPU usage\n",
        "if torch.cuda.device_count() > 1:\n",
        "    model = nn.DataParallel(model)\n",
        "\n",
        "# ðŸš€ Loss Function & Optimizer\n",
        "criterion = nn.HuberLoss(delta=1.0)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.005)  # Increased learning rate for faster convergence\n",
        "\n",
        "# ðŸš€ Training Loop (Optimized for Speed)\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for x_batch, y_batch in train_loader:\n",
        "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(x_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}] - Parallel Loss: {total_loss:.4f}')\n",
        "\n",
        "# ðŸš€ End Timer\n",
        "parallel_time = time.time() - start_time\n",
        "print(f\"ðŸ”¥ Optimized Parallel Execution Time: {parallel_time:.2f} seconds\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert predictions from 0-1 scale back to 1-5\n",
        "def convert_predictions(preds):\n",
        "    return (preds * 4) + 1  # Scale back to 1-5\n",
        "  # ðŸš€ Convert Predictions Back to 1-5 Scale (Parallel Execution)\n",
        "model.eval()  # Set model to evaluation mode\n",
        "sample_input = torch.tensor([[0.2, -1.1, 0.5, 0.8, 1.3, -0.5]], dtype=torch.float32).to(device)\n",
        "output = model(sample_input)\n",
        "converted_output = convert_predictions(output)\n",
        "\n",
        "print(f\"ðŸ”¥ Raw Model Output (Parallel): {output.item():.4f}\")\n",
        "print(f\"ðŸ”¥ Converted Prediction (Parallel, 1-5 Scale): {converted_output.item():.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODoWhvUS5_88",
        "outputId": "50aefde6-5509-4dd3-e276-02dc5fbacfb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”¥ Raw Model Output (Parallel): 0.0000\n",
            "ðŸ”¥ Converted Prediction (Parallel, 1-5 Scale): 1.00\n"
          ]
        }
      ]
    }
  ]
}